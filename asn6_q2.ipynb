{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "asn6-q2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgpGN74okUb7"
      },
      "source": [
        "# Import Libraries "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgf2d1n7kUb_"
      },
      "source": [
        "Import all the required Tensorflow and Keras libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gahTe7HnkUcA"
      },
      "source": [
        "# THIS VERSION IS FOR TENSORFLOW v2.0 which has keras embedded\n",
        "# Note: Multibackend Keras is being discontinued after version 2.3.5.\n",
        "\n",
        "# These are all the imports we will need.  You shouldn't need anything else.\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import regularizers \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import os as os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset sizes\n",
        "num_train_images = 23000\n",
        "num_validation_images = 2000\n",
        "num_test_images = 399\n",
        "\n",
        "# Some Hyperparameters\n",
        "input_image_size = 256\n",
        "batch_size = 32\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "l2_lambda = 0.01\n",
        "\n",
        "# Parameters derived from hyperparameters\n",
        "training_steps_per_epoch = int(num_train_images/batch_size)\n",
        "validation_steps = int(num_validation_images/batch_size)\n",
        "testing_steps_per_epoch = num_test_images/batch_size\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua5ZqoJckUcD"
      },
      "source": [
        " # Step 1: Load the Inception V3 network, and modify it for transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu12dDN7kUcD"
      },
      "source": [
        "# WRITE THE CODE DEFINING THE NETWORK ARCHITECTURE HERE (Sec. 3.9 in the assignment PDF)\n",
        "\n",
        "# Our model will be Inception V3 with the fully connected layers and ouptut layers at the end of the network removed.\n",
        "# For the convolutional layers we will use pre-trained weights from the ImageNET database.\n",
        "\n",
        "# Instantiate an InceptionV3() object with weights='imagenet', input_shape = (input_image_size, input_image_size, 3), \n",
        "# and include_top=False.  Assign the result to the base_model variable.\n",
        "\n",
        "base_model = [your code here]\n",
        "\n",
        "# Get the output layer of our base model. \n",
        "x = base_model.output\n",
        "\n",
        "# Now we want to add some layers to the end of the base model.  \n",
        "# Given an output layer x, the general syntax for adding a new layer is:\n",
        "#\n",
        "# x = LayerObject()(x)\n",
        "#\n",
        "# where LayerObject() is the constructor for a new layer object.  \n",
        "# The new value for x is the new output layer of the model.\n",
        "\n",
        "# Add a GlobalAveragePooling2D() object to the network.  No parameters are needed when instantiating GlobalAveragePooling2D().\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Add a Flatten() layer to the network.  No parameters are needed when instantiating Flatten().\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Add a Dense() layer.  Dense() is the fully-connected layer object you used in the Question 1.  \n",
        "# Instantiate it so that it has 1024 units, and uses the Relu activation function.\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Add another dense layer with 1 unit and the sigmoid activation function.  This will be your output layer.\n",
        "# Assign the result to the 'predictions' variable.\n",
        "\n",
        "predictions = [your code here]\n",
        "\n",
        "# Wrap our network layers in a model object. This has to be done because the base_model is not a Model() object, it's\n",
        "# just a collection of layer objects, and only Model() objects can be compiled.  Here we just tell the Model object \n",
        "# that its first layer is the input layer of the base Inception V3 model and the output layer is our new sigmoid layer.  \n",
        "# This is all the Model object needs beacuse all the other layer objects already know how they are connected.\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Set all the layers in the base model to be non-trainable.  \n",
        "# This freezes the weights in the convolutional layers so that, when we train,\n",
        "# we are only training the weights for the newly added fully connected layer.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False;\n",
        "        \n",
        "# Create an Adam optimizer object with learning rate equal to learning_rate (defined above);\n",
        "# call Adam() with the parameter lr=learning_rate\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Compile the CNN using model.compile() method.  Use the 'adam' optimizer you created above, and the \n",
        "# 'binary_crossentropy' loss function.  Use the parameter metrics=['accuracy'].  \n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "#Print a Summary of the Architecture using the summary() method.\n",
        "#model.summary()     # If you want to see the model, uncomment this line.  It's really big!\n",
        "\n",
        "print('Model compiled!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zr5DjsPkUcG"
      },
      "source": [
        "# Step 2: Load Images and Prepare the Network for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM3S9VEfkUcG"
      },
      "source": [
        "# This is nearly identical to step 2 from question 1 with a few minor changes (watch for them!)\n",
        "\n",
        "# Create the training dataset generator.  This time do not use shearing or zooming, just horizontal flipping.\n",
        "# Don't forget to rescale the image pixel data.\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Create the validation dataset generator.  It doesn't need any data augmentation.\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Load the training set using train_datagen.flow_from_directory().  Use\n",
        "# target_size = (input_image_size, input_image_size), batch_size = batch_size, and class_mode = 'binary'.\n",
        "\n",
        "[your code here]\n",
        "\n",
        "\n",
        "# Load the validation dataset using validation_datagen.flow_from_directory(). \n",
        "# Use the same parameters as above (except for the directory name).\n",
        "\n",
        "[your code here]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0DKojL-kUcH"
      },
      "source": [
        "# Step 3: Run the CNN Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8m63NGr3kUcI"
      },
      "source": [
        "# Train the CNN using model.fit().  \n",
        "# This works just like in the previous problem -- use the provided model hyperparameters defined in the top block of this notebook.\n",
        "# Note, however, that this time num_epochs has been set to 1.  This means we will only train for one epoch!\n",
        "\n",
        "# This will take a while - maybe 2-3 hours.   On my computer (which is a very new\n",
        "# 8-core macbook pro) it took about 35 minutes training on the CPU (not GPU).  \n",
        "\n",
        "[your code here]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pzFRgV6kUcJ"
      },
      "source": [
        "# Step 4: Save the model and weights for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-CG-UAAkUcK",
        "outputId": "acea194b-3f35-479a-97fc-bdcc0aed28c9"
      },
      "source": [
        "# Save the model using the save() method of the CNN model.\n",
        "# Inception is a big network, so this can take quite a while... \n",
        "# be patient and wait for the message indicating that the model has been saved.\n",
        "\n",
        "# You don't have to code anything here except change the filename if required.\n",
        "\n",
        "model.save('Cat-Dog-transfer-Inception.h5')\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIBOEZeFkUcN"
      },
      "source": [
        " # Step 5: Predict Dog/Cat using the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRU43_kdkUcN"
      },
      "source": [
        "# This can be done in exactly the same way as in Question 1.  Just make sure to load the right model file.\n",
        "\n",
        "# You should get a *very* high classification rate.\n",
        "\n",
        "[your code here]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd9nO6GHkUcN"
      },
      "source": [
        "# Final Remarks\n",
        "\n",
        "This exercise shows the potential advantage of transfer learning.  We were able to use a very large and sophisticated model, but avoid most of the work of training it by using weights trained by someone else on a different, but quite general dataset.  All we had to do was fine-tune the weights of a fresh randomly-initialized fully connected layer.\n",
        "\n",
        "We only used one training epoch, and even though that got us a very good model, we might see improvements if we train for additional epochs (at the cost of that much more time!).\n",
        "\n",
        "We might also be able to improve our model further by fine-tuning the weights of some of the convolutional layers.  For example, we could add a second training phase where we un-freeze the weights of the first few convolutional layers, and train them along with the fully connected layers for a few more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNxK1fgUkUcO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}