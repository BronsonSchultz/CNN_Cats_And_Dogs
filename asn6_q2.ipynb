{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "asn6-q2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BronsonSchultz/487_A6/blob/main/asn6_q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xTkNsLsK9F"
      },
      "source": [
        "# Bronson Schultz, 11231230, bcs269\n",
        "## CMPT 487, A6, Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otqx8fZUsK9K"
      },
      "source": [
        "# Import Libraries "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plcd6PGSsK9L"
      },
      "source": [
        "Import all the required Tensorflow and Keras libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE7DatKIsK9L"
      },
      "source": [
        "# THIS VERSION IS FOR TENSORFLOW v2.0 which has keras embedded\n",
        "# Note: Multibackend Keras is being discontinued after version 2.3.5.\n",
        "\n",
        "# These are all the imports we will need.  You shouldn't need anything else.\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import regularizers \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import os as os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset sizes\n",
        "num_train_images = 23000\n",
        "num_validation_images = 2000\n",
        "num_test_images = 399\n",
        "\n",
        "# Some Hyperparameters\n",
        "input_image_size = 256\n",
        "batch_size = 32\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "l2_lambda = 0.01\n",
        "\n",
        "# Parameters derived from hyperparameters\n",
        "training_steps_per_epoch = int(num_train_images/batch_size)\n",
        "validation_steps = int(num_validation_images/batch_size)\n",
        "testing_steps_per_epoch = num_test_images/batch_size\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJqamGbRsK9M"
      },
      "source": [
        " # Step 1: Load the Inception V3 network, and modify it for transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW5uZ-Y3sK9N",
        "outputId": "8eca900b-6d76-4c27-c050-c8676de01cca"
      },
      "source": [
        "# WRITE THE CODE DEFINING THE NETWORK ARCHITECTURE HERE\n",
        "\n",
        "# Our model will be Inception V3 with the fully connected layers and ouptut layers at the end of the network removed.\n",
        "# For the convolutional layers we will use pre-trained weights from the ImageNET database.\n",
        "\n",
        "# Instantiate an InceptionV3()\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    weights='imagenet',\n",
        "    input_shape=((input_image_size, input_image_size, 3)),\n",
        "    include_top=False,\n",
        ")\n",
        "\n",
        "# Get the output layer of our base model. \n",
        "x = base_model.output\n",
        "\n",
        "\n",
        "# Add a GlobalAveragePooling2D() object to the network.\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "\n",
        "# Add a Flatten() layer to the network.\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "\n",
        "# Add a Dense() layer.\n",
        "# Instantiate it so that it has 1024 units, and uses the Relu activation function.\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "\n",
        "# Add another dense layer with 1 unit and the sigmoid activation function.  This will be your output layer.\n",
        "# Assign the result to the 'predictions' variable.\n",
        "\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Wrap our network layers in a model object. This has to be done because the base_model is not a Model() object, it's\n",
        "# just a collection of layer objects, and only Model() objects can be compiled.  Here we just tell the Model object \n",
        "# that its first layer is the input layer of the base Inception V3 model and the output layer is our new sigmoid layer.  \n",
        "# This is all the Model object needs beacuse all the other layer objects already know how they are connected.\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Set all the layers in the base model to be non-trainable.  \n",
        "# This freezes the weights in the convolutional layers so that, when we train,\n",
        "# we are only training the weights for the newly added fully connected layer.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False;\n",
        "        \n",
        "# Create an Adam optimizer object with learning rate equal to learning_rate\n",
        "\n",
        "opt = Adam(learning_rate=learning_rate, )\n",
        "\n",
        "\n",
        "# Compile the CNN using model.compile() method.  \n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print('Model compiled!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model compiled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO5IED0isK9Q"
      },
      "source": [
        "# Step 2: Load Images and Prepare the Network for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oLqDxD6sK9R",
        "outputId": "ea9b970a-32b7-4d4b-97de-6fc9c87a231a"
      },
      "source": [
        "# Create the training dataset generator.  This time do not use shearing or zooming, just horizontal flipping.\n",
        "train_data_gen = image.ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "\n",
        "# Create the validation dataset generator.  It doesn't need any data augmentation.\n",
        "valid_data_gen = image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Load the training set using train_datagen.flow_from_directory().\n",
        "train_data = train_data_gen.flow_from_directory(\"train\", target_size=(input_image_size,input_image_size), batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "\n",
        "# Load the validation dataset using validation_datagen.flow_from_directory(). \n",
        "valid_data = valid_data_gen.flow_from_directory(\"valid\", target_size=(input_image_size, input_image_size), batch_size=batch_size, class_mode='binary')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 23000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5a2UABssK9S"
      },
      "source": [
        "# Step 3: Run the CNN Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qz7R_Ry1sK9T",
        "outputId": "670e106b-b71f-4235-9efb-4cd8bcdbfd41"
      },
      "source": [
        "# Train the CNN using model.fit().  \n",
        "# This works just like in the previous problem -- use the provided model hyperparameters defined in the top block of this notebook.\n",
        "# Note, however, that this time num_epochs has been set to 1.  This means we will only train for one epoch!\n",
        "\n",
        "# This will take a while - maybe 2-3 hours.\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    steps_per_epoch=training_steps_per_epoch,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data=valid_data,\n",
        "                    validation_steps=validation_steps,\n",
        "                    verbose=1,     \n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 718 steps, validate for 62 steps\n",
            "718/718 [==============================] - 2126s 3s/step - loss: 0.1662 - accuracy: 0.9343 - val_loss: 0.0486 - val_accuracy: 0.9834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbwluO9EsK9U"
      },
      "source": [
        "# Step 4: Save the model and weights for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "709akTJJsK9V",
        "outputId": "5409753a-cc44-4bb7-90e9-70bc4a2001ee"
      },
      "source": [
        "# Save the model using the save() method of the CNN model.\n",
        "# Inception is a big network, so this can take quite a while... \n",
        "# be patient and wait for the message indicating that the model has been saved.\n",
        "\n",
        "model.save('Cat-Dog-transfer-Inception.h5')\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xjsc8yZsK9W"
      },
      "source": [
        " # Step 5: Predict Dog/Cat using the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOzj6WKFsK9W",
        "outputId": "d6f08ac5-acc2-41f0-fa8d-6e69eb0f25ec"
      },
      "source": [
        "model = load_model(\"Cat-Dog-transfer-Inception.h5\")\n",
        "test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "generator = test_datagen.flow_from_directory(\"test1\", target_size=(input_image_size, input_image_size), batch_size=batch_size, class_mode=None, shuffle=False)\n",
        "\n",
        "probabilities = model.predict_generator(generator)\n",
        "\n",
        "y_pred = np.squeeze(probabilities > 0.5)\n",
        "\n",
        "# number of correct predicts / number\n",
        "accuracy = sum(y_pred == generator.classes) / len(y_pred)\n",
        "print('The classification rate is', accuracy)\n",
        "                                        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 399 images belonging to 2 classes.\n",
            "The classification rate is 0.974937343358396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F28wdxSlsK9X"
      },
      "source": [
        "# Final Remarks\n",
        "\n",
        "This exercise shows the potential advantage of transfer learning.  We were able to use a very large and sophisticated model, but avoid most of the work of training it by using weights trained by someone else on a different, but quite general dataset.  All we had to do was fine-tune the weights of a fresh randomly-initialized fully connected layer.\n",
        "\n",
        "We only used one training epoch, and even though that got us a very good model, we might see improvements if we train for additional epochs (at the cost of that much more time!).\n",
        "\n",
        "We might also be able to improve our model further by fine-tuning the weights of some of the convolutional layers.  For example, we could add a second training phase where we un-freeze the weights of the first few convolutional layers, and train them along with the fully connected layers for a few more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds7-yQ7ssK9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}